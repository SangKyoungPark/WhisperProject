# ğŸ—£ï¸ Whisper + GPT Summary Assistant

A simple voice-to-summary assistant built using OpenAI Whisper for speech recognition and GPT-3.5-turbo for summarization.

---

## âœ¨ Features

- ğŸ§ Converts speech (audio file) into text using Whisper  
- âœ‚ï¸ Summarizes the transcribed text via OpenAI GPT  
- ğŸ§ª Fully script-based, runs locally  
- ğŸ’» Developed on macOS with Python (Anaconda environment)

---

## ğŸ“‚ Project Structure

```
STTProject/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Main execution file (STT + GPT summary)
â”‚   â”œâ”€â”€ audio_sample.mp3    # Sample audio input
â”‚   â””â”€â”€ summarize_module.py # GPT logic module
â”œâ”€â”€ .env                    # API key (not tracked by Git)
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

Install ffmpeg (required by Whisper):

```bash
brew install ffmpeg
```

---

## ğŸ” .env file format

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

Make sure your key is valid. `sk-proj-...` keys may not work for GPT endpoints.

---

## â–¶ï¸ How to Run

```bash
python backend/app.py
```

- Loads Whisper model  
- Transcribes `audio_sample.mp3`  
- Summarizes the result using GPT  
- Displays everything in terminal

---

## ğŸ“Œ Notes

GPT-based summarization may fail if youâ€™re using a restricted `sk-proj-...` key.  
**Recommended:** use a personal `sk-...` key created from [OpenAIâ€™s API page](https://platform.openai.com/account/api-keys).

---

## ğŸ§‘â€ğŸ’» Developer Notes

This project was developed as a prototype assistant for voice summarization.  
I worked entirely in macOS, focused on fast local testing using Whisper and OpenAIâ€™s GPT.  
Next goals include real-time audio input and Flask API deployment.
